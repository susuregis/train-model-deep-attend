{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeWyXlSvYSh8",
        "outputId": "9b278b83-fb5d-4923-8eaa-c7c3bb08ec46"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow torch torchvision timm pyyaml scikit-learn matplotlib seaborn -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thKA7cJJYbn7"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, File, UploadFile, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import JSONResponse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from torch.utils.data import Dataset\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import io\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "from datetime import datetime\n",
        "import base64\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyAHQ0-6Ygm-",
        "outputId": "21a9e909-c5ab-4bf9-f1b0-da7d4fc006b2"
      },
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=\"bJOCz45QyqwU2ubTQNxo\")\n",
        "project = rf.workspace(\"suelen\").project(\"focus-of-attention-aujxc\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsxxKGMBYhd-",
        "outputId": "77ae3773-3a01-4681-fa4e-b89bc040ecda"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    # Dados\n",
        "    img_size = 112\n",
        "\n",
        "    # Treinamento\n",
        "    batch_size = 64\n",
        "    epochs = 10\n",
        "    lr = 0.001\n",
        "\n",
        "    # Hardware\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    num_workers = 2\n",
        "\n",
        "    # Modelo\n",
        "    backbone = 'mobilenetv3_small_100'\n",
        "    hidden_lstm = 64\n",
        "\n",
        "    #  'Focus-of-Attention-1' ou './Focus-of-Attention-1'\n",
        "    dataset_path = 'Focus-of-Attention-1'\n",
        "\n",
        "    classes = []\n",
        "    num_classes = 0\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "print(f\"  - Dataset: {cfg.dataset_path}\")\n",
        "print(f\"  - Device: {cfg.device}\")\n",
        "print(f\"  - Batch size: {cfg.batch_size}\")\n",
        "print(f\"  - Épocas: {cfg.epochs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cld2rfHVYl9K"
      },
      "outputs": [],
      "source": [
        "class RoboflowAttentionDataset(Dataset):\n",
        "    \"\"\"Dataset agrupado: Atento (Frontal) vs Desatento (resto)\"\"\"\n",
        "\n",
        "    def __init__(self, dataset_path, split='train', transform=None):\n",
        "        self.dataset_path = Path(dataset_path)\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "\n",
        "        if split == 'val':\n",
        "            split = 'valid'\n",
        "\n",
        "        self.img_dir = self.dataset_path / split / 'images'\n",
        "        self.label_dir = self.dataset_path / split / 'labels'\n",
        "\n",
        "        # Lê o data.yaml\n",
        "        yaml_path = self.dataset_path / 'data.yaml'\n",
        "        with open(yaml_path, 'r') as f:\n",
        "            data_config = yaml.safe_load(f)\n",
        "\n",
        "        self.original_classes = data_config['names']\n",
        "\n",
        "        # MAPEIA PARA 2 CLASSES\n",
        "        # 0 = Atento (Front Frontal)\n",
        "        # 1 = Desatento (todas as outras)\n",
        "        self.class_mapping = {}\n",
        "        for idx, class_name in enumerate(self.original_classes):\n",
        "            if 'frontal' in class_name.lower():\n",
        "                self.class_mapping[idx] = 0  # ATENTO\n",
        "            else:\n",
        "                self.class_mapping[idx] = 1  # DESATENTO\n",
        "\n",
        "        print(f\"Mapeamento de classes:\")\n",
        "        for orig_idx, orig_name in enumerate(self.original_classes):\n",
        "            new_class = \"ATENTO\" if self.class_mapping[orig_idx] == 0 else \"DESATENTO\"\n",
        "            print(f\"    {orig_name} → {new_class}\")\n",
        "\n",
        "        # Coleta amostras\n",
        "        self.samples = []\n",
        "        if self.img_dir.exists():\n",
        "            for img_path in self.img_dir.glob('*.*'):\n",
        "                if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
        "                    label_path = self.label_dir / f\"{img_path.stem}.txt\"\n",
        "                    if label_path.exists():\n",
        "                        with open(label_path, 'r') as f:\n",
        "                            line = f.readline().strip()\n",
        "                            if line:\n",
        "                                original_class_id = int(line.split()[0])\n",
        "                                # MAPEIA PARA NOVA CLASSE (0=Atento, 1=Desatento)\n",
        "                                new_class_id = self.class_mapping[original_class_id]\n",
        "                                self.samples.append((str(img_path), new_class_id))\n",
        "\n",
        "        print(f\"{split.upper()}: {len(self.samples)} imagens\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def get_class_names(self):\n",
        "        return ['Atento', 'Desatento']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4RjsvfsYqXy"
      },
      "outputs": [],
      "source": [
        "def get_transforms(train=True):\n",
        "    if train:\n",
        "        return transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((cfg.img_size, cfg.img_size)),\n",
        "            transforms.RandomHorizontalFlip(0.5),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((cfg.img_size, cfg.img_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3uvHx3CYt6K",
        "outputId": "af7dc275-18d5-4933-9a64-bb2713ca394f"
      },
      "outputs": [],
      "source": [
        "train_dataset = RoboflowAttentionDataset(\n",
        "    cfg.dataset_path,\n",
        "    split='train',\n",
        "    transform=get_transforms(train=True)\n",
        ")\n",
        "\n",
        "# Validação\n",
        "val_dataset = RoboflowAttentionDataset(\n",
        "    cfg.dataset_path,\n",
        "    split='valid',\n",
        "    transform=get_transforms(train=False)\n",
        ")\n",
        "\n",
        "# Teste\n",
        "test_dataset = RoboflowAttentionDataset(\n",
        "    cfg.dataset_path,\n",
        "    split='test',\n",
        "    transform=get_transforms(train=False)\n",
        ")\n",
        "\n",
        "# Atualiza configurações\n",
        "cfg.classes = train_dataset.get_class_names()\n",
        "cfg.num_classes = len(cfg.classes)\n",
        "\n",
        "print(f\"Classes: {cfg.classes}\")\n",
        "print(f\"Total de classes: {cfg.num_classes}\")\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=cfg.num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=cfg.num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=cfg.num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuU_HficuBIy",
        "outputId": "ae4fa67d-1421-4c8b-cba0-1b9cd0a5d4d2"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Conta classes\n",
        "train_labels = [label for _, label in train_dataset.samples]\n",
        "class_counts = Counter(train_labels)\n",
        "\n",
        "print(f\"Distribuição (Atento/Desatento):\")\n",
        "for class_id in sorted(class_counts.keys()):\n",
        "    count = class_counts[class_id]\n",
        "    pct = (count / len(train_labels)) * 100\n",
        "    print(f\"  {cfg.classes[class_id]}: {count} ({pct:.1f}%)\")\n",
        "\n",
        "# Calcula pesos\n",
        "total = len(train_labels)\n",
        "weights = [total / (len(class_counts) * class_counts[i]) for i in sorted(class_counts.keys())]\n",
        "class_weights_tensor = torch.FloatTensor(weights).to(cfg.device)\n",
        "\n",
        "print(f\"Pesos: {class_weights_tensor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCm09fSAYyPk",
        "outputId": "fa595e65-b636-4191-bfa6-f638cb4f96af"
      },
      "outputs": [],
      "source": [
        "class LightAttentionModel(nn.Module):\n",
        "    \"\"\"Modelo híbrido CNN + LSTM\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=2, hidden_size=64):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cnn = timm.create_model(\n",
        "            cfg.backbone,\n",
        "            pretrained=True,\n",
        "            num_classes=0,\n",
        "            global_pool=''\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.randn(1, 3, cfg.img_size, cfg.img_size)\n",
        "            features = self.cnn(dummy)\n",
        "            self.feature_size = features.shape[1]\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.feature_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(32, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(x.shape) == 4:\n",
        "            x = x.unsqueeze(1)\n",
        "\n",
        "        batch_size, seq_len = x.shape[0], x.shape[1]\n",
        "        x = x.view(batch_size * seq_len, *x.shape[2:])\n",
        "        features = self.cnn(x)\n",
        "        features = self.pool(features).squeeze(-1).squeeze(-1)\n",
        "        features = features.view(batch_size, seq_len, -1)\n",
        "\n",
        "        lstm_out, _ = self.lstm(features)\n",
        "        lstm_out = lstm_out[:, -1, :]\n",
        "\n",
        "        out = self.classifier(lstm_out)\n",
        "        return out\n",
        "\n",
        "model = LightAttentionModel(num_classes=cfg.num_classes, hidden_size=cfg.hidden_lstm)\n",
        "model = model.to(cfg.device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"  - Total parâmetros: {total_params:,}\")\n",
        "print(f\"  - Treináveis: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGuv8FbyY3sI"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader, split_name='Test'):\n",
        "    \"\"\"Avalia o modelo e retorna métricas detalhadas\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc=f'Eval {split_name}'):\n",
        "            images = images.to(cfg.device)\n",
        "            labels = labels.to(cfg.device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    # Métricas\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_preds, average='weighted'\n",
        "    )\n",
        "\n",
        "    print(f\"Resultados {split_name.upper()}\")\n",
        "    print(f\"  Acurácia:  {accuracy*100:.2f}%\")\n",
        "    print(f\"  Precisão:  {precision*100:.2f}%\")\n",
        "    print(f\"  Recall:    {recall*100:.2f}%\")\n",
        "    print(f\"  F1-Score:  {f1*100:.2f}%\")\n",
        "\n",
        "    # Relatório por classe\n",
        "    print(f\"Relatório por Classe:\")\n",
        "    print(classification_report(\n",
        "        all_labels, all_preds,\n",
        "        target_names=cfg.classes,\n",
        "        digits=4\n",
        "    ))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}